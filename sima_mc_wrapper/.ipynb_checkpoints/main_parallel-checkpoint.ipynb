{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAPE Calcium Imaging Preprocessing Pipeline\n",
    "\n",
    "Finds any .tif, .tiff, .h5 files in the requested directory and performs SIMA-based motion correction and fft-based bidirection \n",
    "offset correction, signal extraction, and neuropil correction. This code parallelizes the computation at the session level by passing the multiple file paths (if there are more than one recordings) to the multiprocessing map function. \n",
    "\n",
    "__IMPORTANT RECOMENDATION__: This pipeline requires the user to manually draw regions-of-interest (ROIs) on the mean image (usually the motion-corrected output). __The ROI zip file must end in \"_RoiSet\" with the extension \".zip\"__. If ROIs have not been drawn, it is recommended to use option 2 below (using files_to_analyze.py) and perform the preprocessing in two runs/executions of this code (main_parallel). For the __first run__, perform only the motion correction step. Take the H5 motion-corrected output and load it into FIJI (https://imagej.net/Fiji), manually draw ROIs, and save the ROIs. Then (__second run__) edit files_to_analyze.py now setting signal_extraction and neuropil_correction to True, and rerun this notebook/script (main_parallel).\n",
    "\n",
    "How to run this code\n",
    "------------------------------------\n",
    "\n",
    "__In this jupyter notebook, just run all cells in order (shift + enter). When you reach the last cell, it will prompt the user for input. You have two options:__\n",
    "\n",
    "1) __Input the path to the root directory__ that contains the raw files. For example, if your files are in a folder called analyze_sessions: C:\\Users\\my_user\\analyze_sessions  \n",
    "This will by default attempt to run motion correction, signal extraction, and neuropil extraction. You will encounter an error if ROI masks are not saved to the same directory as the raw data.\n",
    "\n",
    "2) You can also indicate specific files, parameters, and processing steps to include by __editing the python script called files_to_analyze.py__ (in the same directory as this main_parallel.ipynb). Once you have specified the files in files_to_analyze.py and saved, run this notebooks' cells, leave the input blank, and press enter; this code will automatically load the information in files_to_analyze.py.\n",
    "\n",
    "To execute this in command line and follow the same directions as above:  \n",
    "`python main_parallel.py`\n",
    "\n",
    "\n",
    "See these documentations for details about SIMA\n",
    "------------------------------------\n",
    "\n",
    "https://github.com/losonczylab/sima  \n",
    "http://www.losonczylab.org/sima/1.3.2/  \n",
    "https://www.frontiersin.org/articles/10.3389/fninf.2014.00080/full\n",
    "\n",
    "Required Packages\n",
    "-----------------\n",
    "Python 2.7, sima, glob, multiprocessing, numpy, h5py, pickle (optional if want to save displacement file) \n",
    "\n",
    "Custom code requirements: sima_motion_correction, bidi_offset_correction, calculate_neuropil (written by Vijay Namboodiri), files_to_analyze\n",
    "\n",
    "Parameters (Only relevant if using the subfunction batch_process; ignore if using files_to_analyze or using default params by inputting a file directory)\n",
    "----------\n",
    "\n",
    "fdir : string\n",
    "    root file directory containing the raw tif, tiff, h5 files. Note: leave off the last backslash. For example: C:\\Users\\my_user\\analyze_sessions\n",
    "\n",
    "Optional Parameters (Only relevant if using batch_process)\n",
    "-------------------\n",
    "\n",
    "max_disp : list of two entries\n",
    "    Each entry is an int. First entry is the y-axis maximum allowed displacement, second is the x-axis max allowed displacement.\n",
    "    The number of pixel shift for each line cannot go above these values.\n",
    "    Note: 50 pixels is approximately 10% of the FOV (512x512 pixels)\n",
    "    \n",
    "    Defaults to [30, 50]\n",
    "    \n",
    "save_displacement : bool \n",
    "    Whether or not to have SIMA save the calculated displacements over time. def: False; NOTE: if this is switched to True,\n",
    "    it can double the time to perform motion correction.\n",
    "    \n",
    "    Defaults to False\n",
    "    \n",
    "Output\n",
    "-------\n",
    "motion corrected file (in the format of h5) with \"\\_sima_mc\" appended to the end of the file name\n",
    "\n",
    "\"\\*_sima_masks.npy\" : numpy data file  \n",
    "  * 3D array containing 2D masks for each ROI\n",
    "\n",
    "\"\\*_extractedsignals.npy\" : numpy data file  \n",
    "  * array containing pixel-averaged activity time-series for each ROI\n",
    "   \n",
    "\"\\_spatial_weights_*.h5\" : h5 file  \n",
    "  * contains spatial weighting masks of neuropil for each ROI\n",
    "\n",
    "\"\\_neuropil_signals_*.npy\" : numpy data file  \n",
    "  * array containing neuropil signals for each ROI\n",
    "\n",
    "\"\\_neuropil_corrected_signals_*.npy\" : numpy data file  \n",
    "  * array containing neuropil-corrected signals for each ROI\n",
    "\n",
    "output_images : folder containing images  \n",
    "    You will also find a folder containing plots that reflect how each executed preprocessing step performed. Examples are mean images for motion corrected data, ROI masks overlaid on mean images, extracted signals for each ROI, etc..\n",
    "\n",
    "note: * is a wildcard indicating additional characters present in the file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import native python packages\n",
    "import glob\n",
    "from fnmatch import fnmatch\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "\n",
    "# import custom codes\n",
    "import sima_motion_bidi_correction \n",
    "import calculate_neuropil\n",
    "import single_file_process\n",
    "import files_to_analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_process(root_dir, max_disp = [30, 50], save_displacement = False):\n",
    "    \n",
    "    if not root_dir: # if string is empty, load predefined list of files in files_to_analyze\n",
    "        \n",
    "        fparams = files_to_analyze.define_fparams()\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        root_dir = root_dir + '\\\\'\n",
    "\n",
    "        # declare initialize variables to do with finding files to analyze\n",
    "        fparams = []\n",
    "        fpaths = []\n",
    "        types = ['*.tif', '*.tiff', '*.h5']\n",
    "        exclude_strs = ['spatialweights', '_sima_mc', '_trim_dims', '_offset_vals']\n",
    "\n",
    "        # find files to analyze\n",
    "        for path, subdirs, files in os.walk(root_dir): # os.walk grabs all paths and files in subdirectories\n",
    "            for name in files:\n",
    "                # make sure file of any image file\n",
    "                if any([fnmatch(name, ext) for ext in types]) and not any([exclude_str in name for exclude_str in exclude_strs]): # but don't include processed files\n",
    "                    tmp_dict = {}\n",
    "                    tmp_dict['fname'] = name\n",
    "                    tmp_dict['fdir'] = path\n",
    "                    tmp_dict['max_disp'] = max_disp\n",
    "                    tmp_dict['save_displacement'] = save_displacement\n",
    "\n",
    "                    print(tmp_dict['fname'])\n",
    "                    fparams.append(tmp_dict)\n",
    "                    \n",
    "    # print info to console\n",
    "    num_files = len(fparams)\n",
    "    if num_files == 0:\n",
    "        raise Exception(\"No files to analyze!\")\n",
    "    print(str(num_files) + ' files to analyze')\n",
    "    \n",
    "    # determine number of cores to use and initialize parallel pool\n",
    "    num_processes = min(mp.cpu_count(), num_files)\n",
    "    print('Total CPU cores for parallel processing: ' + str(num_processes))\n",
    "    pool = mp.Pool(processes=num_processes)\n",
    "    \n",
    "    # perform parallel processing; pass iterable list of file params to the analysis module selection code\n",
    "    #pool.map(single_file_process.process, fparams)\n",
    "    \n",
    "    ## for testing\n",
    "    for fparam in fparams:\n",
    "        single_file_process.process(fparam) \n",
    "\n",
    "    pool.close()\n",
    "    pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input root directory of tif, tiff, h5 files to analyze; note: Use FORWARD SLASHES to separate folder and leave the last backlash off!!  Otherwise leave blank to use files declared in file_to_analyze.py\n",
      "1 files to analyze\n",
      "Total CPU cores for parallel processing: 1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (10,673) (9,673) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-96a81a5f6100>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'time'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu'if __name__ == \"__main__\":\\n    fdir = raw_input(r\"Input root directory of tif, tiff, h5 files to analyze; note: Use FORWARD SLASHES to separate folder and leave the last backlash off!!  Otherwise leave blank to use files declared in file_to_analyze.py\")\\n    batch_process(fdir)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\stuberadmin\\Anaconda3\\envs\\SIMA_2_7\\lib\\site-packages\\IPython\\core\\interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2116\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2117\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2118\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<C:\\Users\\stuberadmin\\Anaconda3\\envs\\SIMA_2_7\\lib\\site-packages\\decorator.pyc:decorator-gen-61>\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\stuberadmin\\Anaconda3\\envs\\SIMA_2_7\\lib\\site-packages\\IPython\\core\\magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\stuberadmin\\Anaconda3\\envs\\SIMA_2_7\\lib\\site-packages\\IPython\\core\\magics\\execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1191\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1193\u001b[1;33m             \u001b[1;32mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-3cfd470b4c9e>\u001b[0m in \u001b[0;36mbatch_process\u001b[1;34m(root_dir, max_disp, save_displacement)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;31m# perform parallel processing; pass iterable list of file params to the analysis module selection code\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m     \u001b[0mpool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msingle_file_process\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;31m## for testing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\stuberadmin\\Anaconda3\\envs\\SIMA_2_7\\lib\\multiprocessing\\pool.pyc\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[0;32m    251\u001b[0m         '''\n\u001b[0;32m    252\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mRUN\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 253\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mimap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\stuberadmin\\Anaconda3\\envs\\SIMA_2_7\\lib\\multiprocessing\\pool.pyc\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    570\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (10,673) (9,673) "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if __name__ == \"__main__\":\n",
    "    fdir = raw_input(r\"Input root directory of tif, tiff, h5 files to analyze; note: Use FORWARD SLASHES to separate folder and leave the last backlash off!!  Otherwise leave blank to use files declared in file_to_analyze.py\")\n",
    "    batch_process(fdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
