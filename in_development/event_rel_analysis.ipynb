{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as ticker\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allows for automatic setting of x ticks\n",
    "def format_fn(tick_val, tick_pos):\n",
    "    if int(tick_val) in x_tick_indices:\n",
    "        return tvec[int(tick_val)]\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "def format_xy_axes(ax_handle):\n",
    "    ax_handle.xaxis.set_major_formatter(ticker.FuncFormatter(format_fn))\n",
    "    ax_handle.xaxis.set_major_locator(ticker.AutoLocator())\n",
    "    ax_handle.yaxis.set_major_locator(ticker.AutoLocator())\n",
    "    ax_handle.yaxis.set_major_formatter(ticker.ScalarFormatter())\n",
    "    \n",
    "# simple class to update limits as you go through iterations of data\n",
    "class update_lims:\n",
    "    \n",
    "    def __init__(self, lims):\n",
    "        self.lims = lims\n",
    "        \n",
    "    \n",
    "    def update(self, new_lims):\n",
    "        if self.lims[0] > new_lims[0]:\n",
    "            self.lims[0] = new_lims[0]\n",
    "        \n",
    "        if self.lims[1] < new_lims[1]:\n",
    "            self.lims[1] = new_lims[1]\n",
    "\n",
    "    def output(self):\n",
    "        return self.lims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare some fixed constant variables\n",
    "axis_label_size = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicate a file to analyze\n",
    "fname = 'VJ_OFCVTA_7_260_D6' # 'vj_ofc_imageactivate_01_300_stim-013' # \n",
    "fdir = r'C:\\2pData\\Vijay data\\VJ_OFCVTA_7_D8_trained' # r'D:\\20200410_gcamp_chrmine\\vj_ofc_imageactivate_01_300_stim-013' # \n",
    "flag_npil_corr = False # declare which data to load in\n",
    "flag_zscore = True # whether or not to z-score data for plots\n",
    "\n",
    "# set the sampling rate\n",
    "fs = 5\n",
    "\n",
    "if flag_npil_corr == True:\n",
    "    signals_fpath = os.path.join(fdir, \"{}_neuropil_corrected_signals*\".format(fname))\n",
    "    \n",
    "elif flag_npil_corr == False:\n",
    "    signals_fpath = os.path.join(fdir, \"*_extractedsignals*\")\n",
    "\n",
    "save_path = os.path.join(fdir, 'event_rel_analysis_' + fname)\n",
    "\n",
    "utils.check_exist_dir(save_path) # make the save directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trial windowing \n",
    "trial_start_end_sec = np.array([-4, 10]) # trial windowing in seconds relative to ttl-onset/trial-onset\n",
    "baseline_start_end_sec = np.array([trial_start_end_sec[0], -0.5])\n",
    "\n",
    "# convert times to samples and get sample_vector\n",
    "trial_begEnd_samp = trial_start_end_sec*fs # turn trial start/end times to samples\n",
    "trial_svec = np.arange(trial_begEnd_samp[0], trial_begEnd_samp[1])\n",
    "baseline_begEnd_samp = baseline_start_end_sec*fs\n",
    "baseline_svec = (np.arange(baseline_begEnd_samp[0], baseline_begEnd_samp[1]+1, 1) - baseline_begEnd_samp[0]).astype('int')\n",
    "\n",
    "num_samples_trial = len( trial_svec )\n",
    "tvec = np.round(np.linspace(trial_start_end_sec[0], trial_start_end_sec[1], num_samples_trial+1), 1)\n",
    "\n",
    "x_tick_indices = range(len(tvec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(fdir, \"framenumberforevents_{}_*\".format(fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load time-series data\n",
    "glob_signal_files = glob.glob(signals_fpath)\n",
    "if len(glob_signal_files) == 1:\n",
    "    signals = np.squeeze(np.load(glob_signal_files[0]))\n",
    "else:\n",
    "    print('Warning: No or multiple signal files detected; using first detected file')\n",
    "\n",
    "num_rois = signals.shape[0]\n",
    "    \n",
    "#load behavioral data and trial info\n",
    "try:\n",
    "    glob_frame_files = glob.glob(os.path.join(fdir, \"framenumberforevents_{}*\".format(fname))) # look for a file in specified directory\n",
    "    event_frames = pickle.load( open( glob_frame_files[0], \"rb\" ) ) # latin1 b/c original pickle made in python 2\n",
    "\n",
    "except:\n",
    "    print('Cannot find behavioral data file or file path is incorrect; utils.extract_trial_data will throw error.')\n",
    "    \n",
    "all_conditions = event_frames.keys()\n",
    "conditions = [ all_conditions[i] for i in [0, 4, 6] ] # __ USER DEFINE ; for vijay: [0, 4, 6]\n",
    "conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract trial data\n",
    "data_dict = utils.extract_trial_data(signals, trial_begEnd_samp, event_frames, \n",
    "                                     conditions, baseline_start_end_samp = baseline_begEnd_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def calculate_dict_clims(dict, flag_zscore_=False) __\n",
    "\n",
    "# for trial_avg data, get min/max across conditions\n",
    "clims_data = [ np.nanmin( [np.mean(data_dict[key]['data'], axis = 0) for key in data_dict] ), \n",
    "        np.nanmax( [np.mean(data_dict[key]['data'], axis = 0) for key in data_dict] ) ]\n",
    "\n",
    "# for z-scored data, we'd like for the color scale to be centered at 0; first we get color limits\n",
    "tmp_clim = [ np.nanmin( [data_dict[key]['ztrial_avg_data'] for key in data_dict] ), \n",
    "        np.nanmax( [data_dict[key]['ztrial_avg_data'] for key in data_dict] ) ]\n",
    "# then we take the higher of the two magnitudes\n",
    "clims_max = np.max(np.abs(tmp_clim))\n",
    "# and set it as the negative and positive limit for plotting\n",
    "clims_z = [-clims_max*0.6, clims_max*0.6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot trial-resolved heatmap for each ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_subplots = len(conditions)\n",
    "n_columns = 3.0\n",
    "n_rows = int(np.ceil(num_subplots/n_columns))\n",
    "\n",
    "for iROI in range(2):\n",
    " \n",
    "    roi_clims = [ np.nanmin( [np.nanmin(data_dict[cond]['data'][...,iROI,:]) for cond in conditions] ), \n",
    "        np.nanmax( [np.nanmax(data_dict[cond]['data'][...,iROI,:]) for cond in conditions] ) ]\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=n_rows, ncols=int(n_columns), figsize = (15, n_rows*4))\n",
    "    \n",
    "    for idx_cond, cond in enumerate(conditions):\n",
    "        \n",
    "        # determine subplot location index\n",
    "        if n_rows == 1:\n",
    "            subplot_index = idx_cond\n",
    "        else:\n",
    "            subplot_index = np.unravel_index(idx, (n_rows, int(n_columns))) # turn int index to a tuple of array coordinates\n",
    "        \n",
    "        # plot x and y labels for first subplot\n",
    "        if subplot_index == (0, 0) or subplot_index == 0 :\n",
    "            ax[subplot_index].set_ylabel('Trial', fontsize=axis_label_size)\n",
    "            ax[subplot_index].set_xlabel('Time [s]', fontsize=axis_label_size);\n",
    "        \n",
    "        # plot the data\n",
    "        to_plot = np.squeeze(data_dict[cond]['data'][...,iROI,:]) \n",
    "        if len(event_frames[cond]) == 1:\n",
    "            to_plot = to_plot[np.newaxis, :]\n",
    "        \n",
    "        title = 'ROI {}; {}'.format(str(iROI), cond)\n",
    "        im = utils.subplot_heatmap(ax[subplot_index], title, to_plot, cmap='inferno', clims=roi_clims)\n",
    "        format_xy_axes(ax[subplot_index])\n",
    "        \n",
    "    cbar = fig.colorbar(im, ax = ax, shrink = 0.5)\n",
    "    cbar.ax.set_ylabel('Activity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot trial-avged heatmaps (ROI by trial-avg time by activity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_columns = 3.0\n",
    "num_subplots = len(conditions)\n",
    "n_rows = int(np.ceil(num_subplots/n_columns))\n",
    "\n",
    "fig, ax = plt.subplots(nrows=n_rows, ncols=int(n_columns), figsize = (15, n_rows*4))\n",
    "for idx, cond in enumerate(conditions):\n",
    "    \n",
    "    # determine subplot location index\n",
    "    if n_rows == 1:\n",
    "        subplot_index = idx\n",
    "    else:\n",
    "        subplot_index = np.unravel_index(idx, (n_rows, int(n_columns))) # turn int index to a tuple of array coordinates\n",
    "    \n",
    "    # plot x and y labels for first subplot\n",
    "    if subplot_index == (0, 0) or subplot_index == 0 :\n",
    "        ax[subplot_index].set_ylabel('ROI #', fontsize=axis_label_size)\n",
    "        ax[subplot_index].set_xlabel('Time [s]', fontsize=axis_label_size);\n",
    "    \n",
    "    # plot the data\n",
    "    to_plot = data_dict[cond]['ztrial_avg_data'] # np.mean( data_dict[cond]['data'], axis=0) #\n",
    "        \n",
    "    im = utils.subplot_heatmap(ax[subplot_index], cond, to_plot, clims = clims_z)\n",
    "    format_xy_axes(ax[subplot_index])\n",
    "    \n",
    "cbar = fig.colorbar(im, ax = ax, shrink = 0.5)\n",
    "cbar.ax.set_ylabel('Z-Score Activity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cond in conditions:\n",
    "    roi_trial_avg = np.mean(data_dict[cond]['data'], axis = (0, 1))\n",
    "    \n",
    "    zscore_roi_trial_avg = utils.zscore_(roi_trial_avg, baseline_svec)\n",
    "\n",
    "    sns.lineplot(tvec, np.squeeze(zscore_roi_trial_avg))\n",
    "    \n",
    "plt.ylabel('Z-score Activity', fontsize=axis_label_size)\n",
    "plt.xlabel('Time [s]', fontsize=axis_label_size);\n",
    "plt.legend(conditions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot each neuron's trial averaged response across conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_columns = 3.0\n",
    "num_subplots = len(conditions)\n",
    "n_rows = int(np.ceil(num_subplots/n_columns))\n",
    "\n",
    "fig, ax = plt.subplots(nrows=n_rows, ncols=int(n_columns), figsize = (15, n_rows*4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_frames = {}\n",
    "event_frames['slm_stim'] = np.array([300.])\n",
    "\n",
    "with open(r'D:\\20200410_gcamp_chrmine\\vj_ofc_imageactivate_01_300_stim-013\\framenumberforevents_vj_ofc_imageactivate_01_300_stim-013.pickle', 'wb') as handle:\n",
    "    pickle.dump(event_frames, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
