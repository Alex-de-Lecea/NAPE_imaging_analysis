{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAPE Calcium Imaging Event-Related Analysis\n",
    "\n",
    "Finds any .tif, .tiff, .h5 files in the requested directory and performs SIMA-based motion correction and fft-based bidirection \n",
    "offset correction, signal extraction, and neuropil correction. This code parallelizes the computation at the session level by passing the multiple file paths (if there are more than one recordings) to the multiprocessing map function. \n",
    "\n",
    "\n",
    "How to run this code\n",
    "------------------------------------\n",
    "\n",
    "__In this jupyter notebook, just run all cells in order (shift + enter).__\n",
    "\n",
    "You can indicate specific files, parameters, and processing steps to include by __editing the python script called files_to_analyze_event.py__ (in the same directory as this script). Once you have specified the files in files_to_analyze.py and saved, run this notebooks' cells, leave the input blank, and press enter; this code will automatically load the information in files_to_analyze_event.py.\n",
    "\n",
    "\n",
    "Required Packages\n",
    "-----------------\n",
    "Python 2.7, seaborn, matplotlib, pandas, scikit-learn\n",
    "\n",
    "Custom code requirements: utils\n",
    "\n",
    "Parameters (Only relevant if using the subfunction batch_process; ignore if using files_to_analyze or using default params by inputting a file directory)\n",
    "----------\n",
    "\n",
    "fdir : string\n",
    "    root file directory containing the raw tif, tiff, h5 files. Note: leave off the last backslash. For example: C:\\Users\\my_user\\analyze_sessions\n",
    "\n",
    "Optional Parameters (Only relevant if using batch_process)\n",
    "-------------------\n",
    "\n",
    "max_disp : list of two entries\n",
    "    Each entry is an int. First entry is the y-axis maximum allowed displacement, second is the x-axis max allowed displacement.\n",
    "    The number of pixel shift for each line cannot go above these values.\n",
    "    Note: 50 pixels is approximately 10% of the FOV (512x512 pixels)\n",
    "    \n",
    "    Defaults to [30, 50]\n",
    "    \n",
    "save_displacement : bool \n",
    "    Whether or not to have SIMA save the calculated displacements over time. def: False; NOTE: if this is switched to True,\n",
    "    it can double the time to perform motion correction.\n",
    "    \n",
    "    Defaults to False\n",
    "    \n",
    "Output\n",
    "-------\n",
    "motion corrected file (in the format of h5) with \"\\_sima_mc\" appended to the end of the file name\n",
    "\n",
    "output_images : folder containing images\n",
    "    You will also find a folder containing plots that reflect how each executed preprocessing step performed. Examples are mean images for motion corrected data, ROI masks overlaid on mean images, extracted signals for each ROI, etc..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as ticker\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from __future__ import division # make py2 act like py3 where int division turns into float\n",
    "import matplotlib\n",
    "#important for text to be detected when importing saved figures into illustrator\n",
    "matplotlib.rcParams['pdf.fonttype']=42\n",
    "matplotlib.rcParams['ps.fonttype']=42\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple class to update limits as you go through iterations of data\n",
    "# first call update_lims(first_lims)\n",
    "# then update_lims.update(new_lims)\n",
    "# update_lims.output() outputs lims\n",
    "class update_lims:\n",
    "    \n",
    "    def __init__(self, lims):\n",
    "        self.lims = lims\n",
    "        \n",
    "    \n",
    "    def update(self, new_lims):\n",
    "        if self.lims[0] > new_lims[0]:\n",
    "            self.lims[0] = new_lims[0]\n",
    "        \n",
    "        if self.lims[1] < new_lims[1]:\n",
    "            self.lims[1] = new_lims[1]\n",
    "\n",
    "    def output(self):\n",
    "        return self.lims\n",
    "    \n",
    "    \n",
    "# find 2D subplot index based on a numerical incremented index (ie. idx=3 would be (2,1) for a 2x2 subplot figure)     \n",
    "def subplot_loc(idx, num_rows, num_col):\n",
    "    if n_rows == 1:\n",
    "        subplot_index = idx\n",
    "    else:\n",
    "        subplot_index = np.unravel_index(idx_cond, (n_rows, int(n_columns))) # turn int index to a tuple of array coordinates\n",
    "    return subplot_index\n",
    "\n",
    "# declare some fixed constant variables\n",
    "axis_label_size = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "User-defined variables\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# indicate a file to analyze\n",
    "fname = 'VJ_OFCVTA_7_260_D6' # 'vj_ofc_imageactivate_02_200_006' # \n",
    "fdir = r'C:\\2pData\\Vijay data\\VJ_OFCVTA_7_D8_trained' #  r'D:\\bruker_data\\vj_ofc_imageactivate_02_200\\vj_ofc_imageactivate_02_200_006' #  \n",
    "\n",
    "# set the sampling rate\n",
    "fs = 30\n",
    "\n",
    "# trial windowing \n",
    "trial_start_end_sec = np.array([-5.5, 8]) # trial windowing in seconds relative to ttl-onset/trial-onset, in seconds\n",
    "baseline_start_end_sec = np.array([trial_start_end_sec[0], -0.2])\n",
    "event_dur = 2 # duration of stim/event in seconds\n",
    "\n",
    "# analysis and plotting arguments\n",
    "flag_npil_corr = False # declare which data to load in\n",
    "flag_zscore = True # whether or not to z-score data for plots\n",
    "flag_sort_rois = True\n",
    "if flag_sort_rois:\n",
    "    user_sort_method = 'max_value' # peak_time or max_value\n",
    "    roi_sort_cond = 'plus' # for roi-resolved heatmaps, which condition to sort ROIs by\n",
    "flag_roi_trial_avg_errbar = True # toggle to show error bar on roi- and trial-averaged traces\n",
    "flag_trial_avg_errbar = True # toggle to show error bars on the trial-avg traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if flag_npil_corr == True:\n",
    "    signals_fpath = os.path.join(fdir, \"{}_neuropil_corrected_signals*\".format(fname))\n",
    "    \n",
    "elif flag_npil_corr == False:\n",
    "    signals_fpath = os.path.join(fdir, \"*_extractedsignals*\")\n",
    "\n",
    "save_dir = os.path.join(fdir, 'event_rel_analysis_' + fname)\n",
    "\n",
    "utils.check_exist_dir(save_dir) # make the save directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert times to samples and get sample vector for the trial \n",
    "trial_begEnd_samp = trial_start_end_sec*fs # turn trial start/end times to samples\n",
    "trial_svec = np.arange(trial_begEnd_samp[0], trial_begEnd_samp[1])\n",
    "# and for baseline period\n",
    "baseline_begEnd_samp = baseline_start_end_sec*fs\n",
    "baseline_svec = (np.arange(baseline_begEnd_samp[0], baseline_begEnd_samp[1]+1, 1) - baseline_begEnd_samp[0]).astype('int')\n",
    "\n",
    "# calculate time vector for plot x axes\n",
    "num_samples_trial = len( trial_svec )\n",
    "tvec = np.round(np.linspace(trial_start_end_sec[0], trial_start_end_sec[1], num_samples_trial+1), 2)\n",
    "\n",
    "# find samples and calculations for time 0 for plotting\n",
    "t0_sample = utils.get_tvec_sample(tvec, 0) # grabs the sample index of a given time from a vector of times\n",
    "event_bound_ratio = [(t0_sample-1)/num_samples_trial , (t0_sample+event_dur*fs+1)/num_samples_trial] # fraction of total samples for event start and end; only used for plotting line indicating event duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load time-series data\n",
    "glob_signal_files = glob.glob(signals_fpath)\n",
    "if len(glob_signal_files) == 1:\n",
    "    signals = np.squeeze(np.load(glob_signal_files[0]))\n",
    "else:\n",
    "    print('Warning: No or multiple signal files detected; using first detected file')\n",
    "\n",
    "num_rois = signals.shape[0]\n",
    "    \n",
    "#load behavioral data and trial info\n",
    "try:\n",
    "    glob_frame_files = glob.glob(os.path.join(fdir, \"framenumberforevents_{}*\".format(fname))) # look for a file in specified directory\n",
    "    event_frames = pickle.load( open( glob_frame_files[0], \"rb\" ) ) # latin1 b/c original pickle made in python 2\n",
    "\n",
    "except:\n",
    "    print('Cannot find behavioral data file or file path is incorrect; utils.extract_trial_data will throw error.')\n",
    "\n",
    "# identify conditions to analyze\n",
    "all_conditions = event_frames.keys()\n",
    "conditions = [ condition for condition in all_conditions if event_frames[condition].size > 0 ] # keep conditions that have events\n",
    "\n",
    "tmp  = [ conditions[i] for i in [0, 2, 4] ] # only for vijay data - some of his data are duplicates\n",
    "conditions = tmp\n",
    "print( conditions )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# extract trial data\n",
    "data_dict = utils.extract_trial_data(signals, trial_begEnd_samp, event_frames, \n",
    "                                     conditions, baseline_start_end_samp = baseline_begEnd_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calculate all the color limits for heatmaps; useful for locking color limits across different heatmap subplots\n",
    "\n",
    "# for trial_avg data, get min/max across conditions\n",
    "clims_data = [ np.nanmin( [np.mean(data_dict[key]['data'], axis = 0) for key in data_dict] ), \n",
    "        np.nanmax( [np.mean(data_dict[key]['data'], axis = 0) for key in data_dict] ) ]\n",
    "\n",
    "# for z-scored data, we'd like for the color scale to be centered at 0; first we get color limits\n",
    "tmp_clim = [ np.nanmin( [data_dict[key]['ztrial_avg_data'] for key in data_dict] ), \n",
    "        np.nanmax( [data_dict[key]['ztrial_avg_data'] for key in data_dict] ) ]\n",
    "# then we take the higher of the two magnitudes\n",
    "clims_max = np.max(np.abs(tmp_clim))\n",
    "# and set it as the negative and positive limit for plotting\n",
    "clims_z = [-clims_max*0.3, clims_max*0.3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot trial-resolved heatmap for each ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subplot_trial_heatmap(data_in, conditions, tvec, event_bound_ratio, clims, n_rows, n_columns, \n",
    "                           save_fig = False, axis_label_size=15):\n",
    "    \n",
    "    for idx_cond, cond in enumerate(conditions):\n",
    "        \n",
    "        # set imshow extent to replace x and y axis ticks/labels\n",
    "        plot_extent = [tvec[0], tvec[-1], 0, data_in[cond]['num_trials']]\n",
    "        \n",
    "        # determine subplot location index\n",
    "        subplot_index = subplot_loc(idx_cond, n_rows, n_columns)\n",
    "        \n",
    "        # plot x and y labels for first subplot\n",
    "        if subplot_index == (0, 0) or subplot_index == 0 :\n",
    "            ax[subplot_index].set_ylabel('Trial', fontsize=axis_label_size)\n",
    "            ax[subplot_index].set_xlabel('Time [s]', fontsize=axis_label_size);\n",
    "        \n",
    "        # prep the data\n",
    "        to_plot = np.squeeze(data_in[cond]['data'][...,iROI,:]) \n",
    "        if len(event_frames[cond]) == 1: # accomodates single trial data\n",
    "            to_plot = to_plot[np.newaxis, :]\n",
    "        \n",
    "        # plot the data\n",
    "        title = 'ROI {}; {}'.format(str(iROI), cond)\n",
    "        im = utils.subplot_heatmap(ax[subplot_index], title, to_plot, cmap='inferno', clims=clims, extent_=plot_extent)\n",
    "        \n",
    "        # add meta data lines\n",
    "        ax[subplot_index].axvline(0, color='0.5', alpha=1) # plot vertical line for time zero\n",
    "        ax[subplot_index].annotate('', xy=(event_bound_ratio[0], -0.01), xycoords='axes fraction', \n",
    "                                   xytext=(event_bound_ratio[1], -0.01), \n",
    "                                   arrowprops=dict(arrowstyle=\"-\", color='g'))\n",
    "        \n",
    "    cbar = fig.colorbar(im, ax = ax[subplot_index], shrink = 0.5)\n",
    "    cbar.ax.set_ylabel('Activity')\n",
    "    \n",
    "#def subplot_trial_avg_trace():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_subplots = len(conditions) + 1 # plus one for trial-avg traces\n",
    "n_columns = np.min([num_subplots, 4.0])\n",
    "n_rows = int(np.ceil(num_subplots/n_columns))\n",
    "\n",
    "for iROI in range(2):\n",
    " \n",
    "    roi_clims = [ np.nanmin( [np.nanmin(data_dict[cond]['data'][...,iROI,:]) for cond in conditions] ), \n",
    "        np.nanmax( [np.nanmax(data_dict[cond]['data'][...,iROI,:]) for cond in conditions] ) ]\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=n_rows, ncols=int(n_columns), \n",
    "                           figsize = (n_columns*5, n_rows*4),\n",
    "                           constrained_layout=True)\n",
    "    \n",
    "    subplot_trial_heatmap(data_dict, conditions, tvec, event_bound_ratio, roi_clims, n_rows, n_columns, \n",
    "                           save_fig = False)\n",
    "    \n",
    "    ########## plot last subplot of trial-avg traces\n",
    "    \n",
    "    # determine subplot location index\n",
    "    subplot_index = subplot_loc(num_subplots-1, n_rows, n_columns)\n",
    "\n",
    "    for cond in conditions:\n",
    "        \n",
    "        # prep data to plot\n",
    "        num_trials = data_dict[cond]['num_trials']\n",
    "        to_plot = np.mean(data_dict[cond]['zdata'][:,iROI,:], axis=0)\n",
    "        to_plot_err = np.std(data_dict[cond]['zdata'][:,iROI,:], axis=0)/np.sqrt(num_trials)\n",
    "        \n",
    "        # plot trace\n",
    "        ax[subplot_index].plot(tvec, to_plot)\n",
    "        # plot shaded error\n",
    "        if flag_trial_avg_errbar:\n",
    "            ax[subplot_index].fill_between(tvec, to_plot - to_plot_err, to_plot + to_plot_err,\n",
    "                         alpha=0.5) # this plots the shaded error bar\n",
    "        \n",
    "    # plot x, y labels, and legend\n",
    "    ax[subplot_index].set_ylabel('Z-Score Activity', fontsize=axis_label_size)\n",
    "    ax[subplot_index].set_xlabel('Time [s]', fontsize=axis_label_size)\n",
    "    ax[subplot_index].set_title('ROI # {}; Trial-avg'.format(str(iROI)))\n",
    "    ax[subplot_index].legend(conditions)\n",
    "    ax[subplot_index].autoscale(enable=True, axis='both', tight=True)\n",
    "    ax[subplot_index].axvline(0, color='0.5', alpha=0.65) # plot vertical line for time zero\n",
    "    ax[subplot_index].annotate('', xy=(event_bound_ratio[0], -0.01), xycoords='axes fraction', \n",
    "                                   xytext=(event_bound_ratio[1], -0.01), \n",
    "                                   arrowprops=dict(arrowstyle=\"-\", color='g'))\n",
    "    \n",
    "    fig.savefig( os.path.join(save_dir,'roi_{}_activity.png'.format(str(iROI))) ); \n",
    "    fig.savefig( os.path.join(save_dir,'roi_{}_activity.pdf'.format(str(iROI))) );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot trial-avged heatmaps (ROI by trial-avg time by activity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to find closest sample when a time occurs in a time vector\n",
    "tvec2samp = lambda tvec, time: np.argmin(np.abs(tvec - time))\n",
    "\n",
    "# sorts \n",
    "def sort_heatmap_peaks(data, tvec, sort_epoch_start_time, sort_epoch_end_time, sort_method = 'peak_time'):\n",
    "    \n",
    "    # find start/end samples for epoch\n",
    "    sort_epoch_start_samp = tvec2samp(tvec, sort_epoch_start_time)\n",
    "    sort_epoch_end_samp = tvec2samp(tvec, sort_epoch_end_time)\n",
    "    \n",
    "    if sort_method == 'peak_time':\n",
    "        epoch_peak_samp = np.argmax(data[:,sort_epoch_start_samp:sort_epoch_end_samp], axis=1)\n",
    "        final_sorting = np.argsort(epoch_peak_samp)\n",
    "    elif sort_method == 'max_value':\n",
    "        time_max = np.max(data[:,sort_epoch_start_samp:sort_epoch_end_samp], axis=1)\n",
    "        final_sorting = np.argsort(time_max)[::-1]\n",
    "\n",
    "    return final_sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interesting_rois = [ 0, 1, 2, 23, 22, 11, 9, 5, 6, 7, 3, 4, 8, 12, 14, 15, 16, 17]#[35, 30, 20, 4] #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if flag_sort_rois:\n",
    "    # returns new order of rois sorted using the data and method supplied in the specified window\n",
    "    sorted_roi_order = sort_heatmap_peaks(data_dict[roi_sort_cond]['ztrial_avg_data'], tvec, \n",
    "                       sort_epoch_start_time=0, \n",
    "                       sort_epoch_end_time = trial_start_end_sec[-1], \n",
    "                       sort_method = user_sort_method)\n",
    "    # finds corresponding interesting roi order after sorting\n",
    "    interesting_rois = np.in1d(sorted_roi_order, interesting_rois).nonzero()[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_trial_avg_heatmap(data_in, conditions, tvec, event_bound_ratio, clims, sorted_roi_order = None, \n",
    "                           rois_oi = None, save_fig = False, axis_label_size=15):\n",
    "    \n",
    "    num_subplots = len(conditions)\n",
    "    n_columns = np.min([num_subplots, 3.0])\n",
    "    n_rows = int(np.ceil(num_subplots/n_columns))\n",
    "\n",
    "    # set imshow extent to replace x and y axis ticks/labels (replace samples with time)\n",
    "    plot_extent = [tvec[0], tvec[-1], num_rois, 0 ]\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=n_rows, ncols=int(n_columns), figsize = (n_columns*5, n_rows*4))\n",
    "    if not isinstance(ax,np.ndarray): # this is here to make the code below compatible with indexing a single subplot object\n",
    "        ax = [ax]\n",
    "\n",
    "    for idx, cond in enumerate(conditions):\n",
    "\n",
    "        # determine subplot location index\n",
    "        if n_rows == 1:\n",
    "            subplot_index = idx\n",
    "        else:\n",
    "            subplot_index = np.unravel_index(idx, (n_rows, int(n_columns))) # turn int index to a tuple of array coordinates\n",
    "\n",
    "        # plot x and y labels for first subplot\n",
    "        if subplot_index == (0, 0) or subplot_index == 0 :\n",
    "            ax[subplot_index].set_ylabel('ROI #', fontsize=axis_label_size)\n",
    "            ax[subplot_index].set_xlabel('Time [s]', fontsize=axis_label_size);\n",
    "\n",
    "        # plot the data\n",
    "        if sorted_roi_order is not None:\n",
    "            roi_order = sorted_roi_order\n",
    "        else:\n",
    "            roi_order = slice(0, num_rois)\n",
    "        to_plot = data_in[cond]['ztrial_avg_data'][roi_order,:] # np.mean( data_dict[cond]['data'], axis=0) #\n",
    "\n",
    "        im = utils.subplot_heatmap(ax[subplot_index], cond, to_plot, clims = clims, extent_=plot_extent)\n",
    "        ax[subplot_index].axvline(0, color='k', alpha=0.3) # plot vertical line for time zero\n",
    "        ax[subplot_index].annotate('', xy=(event_bound_ratio[0], -0.01), xycoords='axes fraction', \n",
    "                                       xytext=(event_bound_ratio[1], -0.01), \n",
    "                                       arrowprops=dict(arrowstyle=\"-\", color='g'))\n",
    "        if rois_oi is not None:\n",
    "            for ROI_OI in rois_oi:\n",
    "                ax[subplot_index].annotate('', xy=(1.005, 1-(ROI_OI/num_rois)-0.015), xycoords='axes fraction', \n",
    "                                           xytext=(1.08, 1-(ROI_OI/num_rois)-0.015), \n",
    "                                           arrowprops=dict(arrowstyle=\"->\", color='k'))\n",
    "\n",
    "    cbar = fig.colorbar(im, ax = ax, shrink = 0.5)\n",
    "    cbar.ax.set_ylabel('Z-Score Activity')\n",
    "    \n",
    "    if save_fig is True:\n",
    "        fig.savefig(os.path.join(save_dir,'trial_avg_heatmap.png')); fig.savefig(os.path.join(save_dir,'trial_avg_heatmap.pdf'));\n",
    "    \n",
    "plot_trial_avg_heatmap(data_dict, conditions, tvec, event_bound_ratio, clims = clims_z,\n",
    "                       sorted_roi_order = sorted_roi_order, rois_oi = interesting_rois, save_fig = False)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot trial- and ROI-averaged traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for cond in conditions:\n",
    "    # first trial avg the data\n",
    "    trial_avg = np.mean(data_dict[cond]['data'], axis=0)\n",
    "    \n",
    "    # z-score trial-avg data for each respective ROI\n",
    "    # apply zscore function to each row of data\n",
    "    app_axis = 1 \n",
    "    zscore_trial_avg = np.apply_along_axis(utils.zscore_, app_axis, trial_avg, baseline_svec)\n",
    "    \n",
    "    # take avg/std across ROIs\n",
    "    zscore_roi_trial_avg = np.mean(zscore_trial_avg, axis=0)\n",
    "    zscore_roi_trial_std = np.std(zscore_trial_avg, axis=0)\n",
    "     \n",
    "    to_plot = np.squeeze(zscore_roi_trial_avg)\n",
    "    to_plot_err = np.squeeze(zscore_roi_trial_std)/np.sqrt(num_rois)\n",
    "    \n",
    "    fig = sns.lineplot(tvec, to_plot)\n",
    "    if flag_roi_trial_avg_errbar:\n",
    "        fig.fill_between(tvec, to_plot - to_plot_err, to_plot + to_plot_err,\n",
    "                     alpha=0.2) # this plots the shaded error bar\n",
    "    \n",
    "fig.set_ylabel('Z-score Activity', fontsize=axis_label_size)\n",
    "fig.set_xlabel('Time [s]', fontsize=axis_label_size);\n",
    "fig.legend(conditions);\n",
    "fig.axvline(0, color='0.5', alpha=0.65) # plot vertical line for time zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for saving behav data\n",
    "\n",
    "# import numpy as np\n",
    "# import pickle\n",
    "# event_frames = {}\n",
    "# event_frames['slm_stim'] = np.array([254.])\n",
    "\n",
    "# with open(r'D:\\20200410_gcamp_chrmine\\vj_ofc_imageactivate_01_300_stim-009\\framenumberforevents_vj_ofc_imageactivate_01_300_stim-009.pickle', 'wb') as handle:\n",
    "#     pickle.dump(event_frames, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
