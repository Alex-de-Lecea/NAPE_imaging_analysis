{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import math\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC, SVR, LinearSVC\n",
    "from sklearn.metrics import accuracy_score, silhouette_score, adjusted_rand_score, silhouette_samples\n",
    "from sklearn.cluster import AgglomerativeClustering, SpectralClustering, KMeans\n",
    "from sklearn.model_selection import KFold, LeaveOneOut, train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn import linear_model\n",
    "from sklearn.manifold import TSNE\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from patsy import (ModelDesc, EvalEnvironment, Term, EvalFactor, LookupFactor, dmatrices, INTERCEPT)\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.colorbar as colorbar\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_plot_graphics(ax):\n",
    "    [i.set_linewidth(0.5) for i in ax.spines.itervalues()]\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    return ax\n",
    "\n",
    "def fit_regression(x, y):\n",
    "    lm = sm.OLS(y, sm.add_constant(x)).fit()\n",
    "    x_range = sm.add_constant(np.array([x.min(), x.max()]))\n",
    "    x_range_pred = lm.predict(x_range)\n",
    "    return lm.pvalues[1], lm.params[1], x_range[:,1], x_range_pred, lm.rsquared\n",
    "\n",
    "def CDFplot(x, ax, **kwargs):\n",
    "    x = np.array(x)\n",
    "    ix=np.argsort(x)\n",
    "    ax.plot(x[ix], ECDF(x)(x)[ix], **kwargs)\n",
    "    return ax\n",
    "\n",
    "def fit_regression_and_plot(x, y, ax, plot_label='', color='k', linecolor='r', markersize=3,\n",
    "                            show_pval=True):\n",
    "    #linetype is a string like 'bo'\n",
    "    pvalue, slope, temp, temppred, R2 = fit_regression(x, y)   \n",
    "    if show_pval:\n",
    "        plot_label = '%s p=%.2e\\nr=%.3f'% (plot_label, pvalue, np.sign(slope)*np.sqrt(R2))\n",
    "    else:\n",
    "        plot_label = '%s r=%.3f'% (plot_label, np.sign(slope)*np.sqrt(R2))\n",
    "    ax.scatter(x, y, color=color, label=plot_label, s=markersize)\n",
    "    ax.plot(temp, temppred, color=linecolor)\n",
    "    return ax, slope, pvalue, R2\n",
    "\n",
    "def make_silhouette_plot(X, cluster_labels):\n",
    "    \n",
    "    n_clusters = len(set(cluster_labels))\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    fig.set_size_inches(4, 4)\n",
    "\n",
    "    # The 1st subplot is the silhouette plot\n",
    "    # The silhouette coefficient can range from -1, 1 but in this example all\n",
    "    # lie within [-0.1, 1]\n",
    "    ax.set_xlim([-0.4, 1])\n",
    "    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "    # plots of individual clusters, to demarcate them clearly.\n",
    "    ax.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
    "    silhouette_avg = silhouette_score(X, cluster_labels, metric='cosine')\n",
    "\n",
    "    # Compute the silhouette scores for each sample\n",
    "    sample_silhouette_values = silhouette_samples(X, cluster_labels, metric='cosine')\n",
    "\n",
    "    y_lower = 10\n",
    "    for i in range(n_clusters):\n",
    "        # Aggregate the silhouette scores for samples belonging to\n",
    "        # cluster i, and sort them\n",
    "        ith_cluster_silhouette_values = \\\n",
    "            sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = colors_for_cluster[i]\n",
    "        ax.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                          0, ith_cluster_silhouette_values,\n",
    "                          facecolor=color, edgecolor=color, alpha=0.9)\n",
    "\n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        ax.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i+1))\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    ax.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    ax.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    # The vertical line for average silhouette score of all the values\n",
    "    ax.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    ax.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax.set_xticks([-0.4, -0.2, 0, 0.2, 0.4, 0.6, 0.8, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_string = 'normal_cycle_female_23062020_140612_'\n",
    "normalization = 'mean'\n",
    "signal_type = \"signal_norm\" #'signal_norm'  \n",
    "analysis_condition = ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "basedir = r'\\\\172.25.144.34\\LabCommon\\Ken\\data\\2pImaging\\result\\result_pickle' # folder containing code and data\n",
    "populationdata = np.load(os.path.join(basedir, 'normal_cycle_female_23062020_140612_Alignedtotrial_meansignal_norm_sucrose_low_high estrogen.npy'),allow_pickle = True)\n",
    "print(str(populationdata.shape[0])+\" cells were analyzed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'C:\\2pData\\Vijay data\\VJ_OFCVTA_7_D8_trained\\event_rel_analysis_VJ_OFCVTA_7_260_D6\\event_data_dict.pkl', 'rb') as pkl_handle:\n",
    "    data_dict = pickle.load(pkl_handle)\n",
    "    \n",
    "populationdata = np.concatenate([data_dict[condition]['ztrial_avg_data'] for condition in data_dict.keys()[1:]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict[condition]['num_samples']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "framerate = 5\n",
    "pre_window_size = 2*framerate # 3 seconds multipled by 5 frames. Corresponds to baseline prior to cues.\n",
    "window_size = populationdata.shape[1]/2 # Total number of frames plotted around a cue\n",
    "frames_to_reward = 5*framerate # 3 seconds until reward after CS+\n",
    "\n",
    "sortwindow = [pre_window_size, pre_window_size + frames_to_reward] # Sort responses between first lick and 10 seconds.\n",
    "sortresponse = np.argsort(np.mean(populationdata[:,sortwindow[0]:sortwindow[1]], axis=1))[::-1]\n",
    "# sortresponse corresponds to an ordering of the neurons based on their average response in the sortwindow\n",
    "\n",
    "cmax = 0.3 # Maximum colormap value. \n",
    "\n",
    "trial_types = data_dict.keys()[1:]# ['low estrogen', 'high estrogen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,2,figsize=(3*2,3*2), sharex='all', sharey='row')\n",
    "cbar_ax = fig.add_axes([0.86, .3, .01, .4])\n",
    "cbar_ax.tick_params(width=0.5) \n",
    "\n",
    "for t in range(len(trial_types)):\n",
    "    axs[0,t].set_title(trial_types[t])\n",
    "    ax = axs[0,t]\n",
    "    sns.heatmap(populationdata[sortresponse, t*window_size: (t+1)*window_size],\n",
    "                ax=ax,\n",
    "                cmap=plt.get_cmap('coolwarm'),\n",
    "                vmin=-cmax,\n",
    "                vmax=cmax,\n",
    "                cbar=(t==0),\n",
    "                cbar_ax=cbar_ax if (t==0) else None,\n",
    "                cbar_kws={'label': 'Normalized fluorescence'})\n",
    "    ax.grid(False)\n",
    "    ax.tick_params(width=0.5)   \n",
    "    ax.set_xticks([0, pre_window_size, pre_window_size + frames_to_reward, window_size]) \n",
    "    ax.set_xticklabels([str(int((a-pre_window_size+0.0)/framerate))\n",
    "                                     for a in [0, pre_window_size,\n",
    "                                               pre_window_size + frames_to_reward, window_size]])\n",
    "    ax.set_yticks([])\n",
    "    ax.axvline(pre_window_size, linestyle='--', color='k', linewidth=0.5)    \n",
    "    ax.axvline(pre_window_size + frames_to_reward, linestyle='--', color='k', linewidth=0.5)    \n",
    "    ax.set_xlabel('Time from cue (s)')\n",
    "    \n",
    "        \n",
    "    ax = axs[1,t]\n",
    "    sns.tsplot(populationdata[sortresponse, t*window_size:(t+1)*window_size],\n",
    "               ax=ax)\n",
    "    ax.axvline(pre_window_size, linestyle='--', color='k', linewidth=0.5)    \n",
    "    ax.axvline(pre_window_size + frames_to_reward, linestyle='--', color='k', linewidth=0.5)    \n",
    "    ax.set_xlabel('Time from cue (s)')\n",
    "    ax.set_xticks([0, pre_window_size, pre_window_size + frames_to_reward, window_size]) \n",
    "    ax.set_xticklabels([str(int((a-pre_window_size+0.0)/framerate))\n",
    "                                     for a in [0, pre_window_size,\n",
    "                                               pre_window_size + frames_to_reward, window_size]])\n",
    "    \n",
    "axs[0,0].set_ylabel('Neurons')\n",
    "axs[1,0].set_ylabel('Mean norm. fluor.')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(right=0.82)\n",
    "# f.savefig(os.path.join(indir, 'results', tempstr+'.pdf'), format='pdf')\n",
    "#fig.savefig(os.path.join(summaryfigdir, dt_string+'_'+clusterkey + '+' + trial_types[0] + '_'+trial_types[1]+'.png'), format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_savedpca_or_dopca = 'dopca'\n",
    "# Select 'dopca' for doing PCA on the data. Select 'savedpca' for loading my previous results\n",
    "\n",
    "if load_savedpca_or_dopca == 'dopca':\n",
    "    pca = PCA(n_components=min(populationdata.shape[0],populationdata.shape[1]), whiten=True)\n",
    "    pca.fit(populationdata) \n",
    "    with open(os.path.join(basedir, 'pcaresults.pickle'), 'wb') as f:\n",
    "        pickle.dump(pca, f)\n",
    "elif load_savedpca_or_dopca == 'savedpca':\n",
    "    with open(os.path.join(basedir, 'OFCCaMKII_pcaresults.pickle'), 'rb') as f:\n",
    "        pca = pickle.load(f)\n",
    "    \n",
    "transformed_data = pca.transform(populationdata)\n",
    "#np.save(os.path.join(basedir, dt_string+'_'+clusterkey+'_' + \"transformed_data.npy\"),transformed_data)\n",
    "\n",
    "pca_vectors = pca.components_\n",
    "print 'Number of PCs = %d'%(pca_vectors.shape[0])\n",
    "\n",
    "x = 100*pca.explained_variance_ratio_\n",
    "xprime = x - (x[0] + (x[-1]-x[0])/(x.size-1)*np.arange(x.size))\n",
    "num_retained_pcs = np.argmin(xprime)\n",
    "# Number of PCs to be kept is defined as the number at which the \n",
    "# scree plot bends. This is done by simply bending the scree plot\n",
    "# around the line joining (1, variance explained by first PC) and\n",
    "# (num of PCs, variance explained by the last PC) and finding the \n",
    "# number of components just below the minimum of this rotated plot\n",
    "print 'Number of PCs to keep = %d'%(num_retained_pcs)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(2,2))\n",
    "ax.plot(np.arange(pca.explained_variance_ratio_.shape[0]).astype(int)+1, x, 'k')\n",
    "ax.set_ylabel('Percentage of\\nvariance explained')\n",
    "ax.set_xlabel('PC number')\n",
    "ax.axvline(num_retained_pcs, linestyle='--', color='k', linewidth=0.5)\n",
    "ax.set_title('Scree plot')\n",
    "# ax.set_xlim([0,50])\n",
    "[i.set_linewidth(0.5) for i in ax.spines.itervalues()]\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "\n",
    "fig.subplots_adjust(left=0.3)\n",
    "fig.subplots_adjust(right=0.98)\n",
    "fig.subplots_adjust(bottom=0.25)\n",
    "fig.subplots_adjust(top=0.9)\n",
    "#fig.savefig(os.path.join(summaryfigdir, dt_string+'_'+clusterkey+'_' + trial_types[0] + '_'+trial_types[1]+'_scree_plot.png'), format='png', dpi=300)\n",
    "\n",
    "\n",
    "colors_for_key = {}\n",
    "colors_for_key[trial_types[0]] = (0,0.5,1)\n",
    "colors_for_key[trial_types[1]] = (1,0.5,0)\n",
    "\n",
    "numcols = 3.0\n",
    "fig, axs = plt.subplots(int(np.ceil(num_retained_pcs/numcols)), int(numcols), sharey='all',\n",
    "                        figsize=(2*numcols, 2*int(np.ceil(num_retained_pcs/numcols))))\n",
    "for pc in range(num_retained_pcs):\n",
    "    ax = axs.flat[pc]\n",
    "    for k, tempkey in enumerate(trial_types):\n",
    "        ax.plot(pca_vectors[pc, k*window_size:(k+1)*window_size], color=colors_for_key[tempkey],\n",
    "                label='PC %d: %s'%(pc+1, tempkey))\n",
    "    ax.axvline(pre_window_size, linestyle='--', color='k', linewidth=1)\n",
    "    ax.annotate(s='PC %d'%(pc+1), xy=(0.45, 0.06), xytext=(0.45, 0.06), xycoords='axes fraction',\n",
    "                textcoords='axes fraction', multialignment='center', size='large')\n",
    "    if pc >= num_retained_pcs-numcols:\n",
    "        ax.set_xticks([0, pre_window_size,\n",
    "                       pre_window_size + frames_to_reward, window_size])\n",
    "        ax.set_xticklabels([str(int((a-pre_window_size+0.0)/framerate))\n",
    "                             for a in [0, pre_window_size,\n",
    "                                       pre_window_size + frames_to_reward, window_size]])\n",
    "    else:\n",
    "        ax.set_xticks([])\n",
    "        ax.xaxis.set_ticks_position('none')\n",
    "    if pc%numcols:\n",
    "        ax.yaxis.set_ticks_position('none')\n",
    "    [i.set_linewidth(0.5) for i in ax.spines.itervalues()]\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "\n",
    "\n",
    "fig.text(0.5, 0.05, 'Time from cue (s)', horizontalalignment='center', rotation='horizontal')\n",
    "fig.text(0.02, 0.6, 'PCA weights', verticalalignment='center', rotation='vertical')\n",
    "fig.tight_layout()\n",
    "for ax in axs.flat[num_retained_pcs:]:\n",
    "    ax.set_visible(False)\n",
    "\n",
    "fig.subplots_adjust(wspace=0.08, hspace=0.08)\n",
    "fig.subplots_adjust(bottom=0.13)\n",
    "#fig.savefig(os.path.join(summaryfigdir, dt_string+'_'+clusterkey+'_' +  trial_types[0] + '_'+trial_types[1]+'_PCA.png'), format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_n_clusters = 4# Maximum number of clusters expected. I already ran this with up to 20 clusters and know\n",
    "# that the optimal number is 9. So, I am leaving this at 11. In your data, might be worth increasing this, but\n",
    "# it will take more time to run.\n",
    "\n",
    "possible_n_clusters = np.arange(2, max_n_clusters+1) #This requires a minimum of 2 clusters.\n",
    "# When the data contain no clusters at all, it will be quite visible when inspecting the two obtained clusters, \n",
    "# as the responses of the clusters will be quite similar. This will also be visible when plotting the data in\n",
    "# the reduced dimensionality PC space (done below).\n",
    "\n",
    "\n",
    "possible_n_nearest_neighbors = np.array([30,40,30,50,60]) # This should be selected for each dataset\n",
    "# appropriately. When 4813 neurons are present, the above number of nearest neighbors provides a good sweep of the\n",
    "# parameter space. But it will need to be changed for other data.\n",
    "    \n",
    "silhouette_scores = np.nan*np.ones((possible_n_clusters.size,\n",
    "                                    possible_n_nearest_neighbors.size))\n",
    "\n",
    "for n_clustersidx, n_clusters in enumerate(possible_n_clusters):\n",
    "    for nnidx, nn in enumerate(possible_n_nearest_neighbors):\n",
    "        model = SpectralClustering(n_clusters=n_clusters, affinity='nearest_neighbors', n_neighbors=nn)\n",
    "        model.fit(transformed_data[:,:num_retained_pcs])\n",
    "        silhouette_scores[n_clustersidx, nnidx] = silhouette_score(transformed_data[:,:num_retained_pcs],\n",
    "                                                                   model.labels_,\n",
    "                                                                   metric='cosine')\n",
    "        print 'Done with numclusters = %d, num nearest neighbors = %d: score = %.3f'%(n_clusters,\n",
    "                                                                                      nn,\n",
    "                                                                                      silhouette_scores[n_clustersidx,                                                                           \n",
    "                                                                                                        nnidx])\n",
    "\n",
    "print 'Done with model fitting'\n",
    "\n",
    "silhouette_dict = {}\n",
    "silhouette_dict['possible_n_clusters'] = possible_n_clusters\n",
    "silhouette_dict['possible_n_nearest_neighbors'] = possible_n_nearest_neighbors\n",
    "silhouette_dict['silhouette_scores'] = silhouette_scores\n",
    "silhouette_dict['shape'] = 'cluster_nn'\n",
    "#with open(os.path.join(basedir,dt_string+'_'+ clusterkey+'_' +  'silhouette_scores.pickle'), 'wb') as f:\n",
    "#    pickle.dump(temp, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(os.path.join(basedir, dt_string+'_'+ clusterkey+'_' + 'silhouette_scores.pickle'), 'rb') as f:\n",
    "#    silhouette_scores = pickle.load(f)\n",
    "    \n",
    "# transformed_data = np.load(os.path.join(r'\\\\172.25.144.34\\LabCommon\\Ken\\data\\2pImaging\\result\\result_pickle', dt_string+'_'+ clusterkey+'_' + 'transformed_data.npy'))\n",
    "\n",
    "# Identify optimal parameters from the above parameter space\n",
    "temp = np.where(silhouette_dict['silhouette_scores']==np.nanmax(silhouette_dict['silhouette_scores']))\n",
    "n_clusters = silhouette_dict['possible_n_clusters'][temp[0][0]]\n",
    "n_nearest_neighbors = silhouette_dict['possible_n_nearest_neighbors'][temp[1][0]]\n",
    "\n",
    "print n_clusters, n_nearest_neighbors\n",
    "\n",
    "# Redo clustering with these optimal parameters\n",
    "model = SpectralClustering(n_clusters=n_clusters,\n",
    "                           affinity='nearest_neighbors',\n",
    "                           n_neighbors=n_nearest_neighbors)\n",
    "\n",
    "# model = KMeans(n_clusters=n_clusters)\n",
    "\n",
    "# model = AgglomerativeClustering(n_clusters=9,\n",
    "#                                 affinity='l1',\n",
    "#                                 linkage='average')\n",
    "\n",
    "model.fit(transformed_data[:,:num_retained_pcs])\n",
    "\n",
    "temp = silhouette_score(transformed_data[:,:num_retained_pcs], model.labels_, metric='cosine')\n",
    "\n",
    "print 'Number of clusters = %d, average silhouette = %.3f'%(len(set(model.labels_)), temp)\n",
    "\n",
    "# Save this optimal clustering model.\n",
    "# with open(os.path.join(basedir, 'clusteringmodel.pickle'), 'wb') as f:\n",
    "#     pickle.dump(model, f)\n",
    "\n",
    "          \n",
    "# Since the clustering labels are arbitrary, I rename the clusters so that the first cluster will have the most\n",
    "# positive response and the last cluster will have the most negative response.\n",
    "def reorder_clusters(rawlabels):\n",
    "    uniquelabels = list(set(rawlabels))\n",
    "    responses = np.nan*np.ones((len(uniquelabels),))\n",
    "    for l, label in enumerate(uniquelabels):\n",
    "        responses[l] = np.mean(populationdata[rawlabels==label, pre_window_size:2*pre_window_size])\n",
    "    temp = np.argsort(responses).astype(int)[::-1]\n",
    "    temp = np.array([np.where(temp==a)[0][0] for a in uniquelabels])\n",
    "    outputlabels = np.array([temp[a] for a in list(np.digitize(rawlabels, uniquelabels)-1)])\n",
    "    return outputlabels\n",
    "newlabels = reorder_clusters(model.labels_)\n",
    "\n",
    "# Create a new variable containing all unique cluster labels\n",
    "uniquelabels = list(set(newlabels))\n",
    "\n",
    "# np.save(os.path.join(summarydictdir, dt_string+'_'+ clusterkey+'_' + 'spectral_clusterlabels.npy'), newlabels)\n",
    "\n",
    "colors_for_cluster = [[0.933, 0.250, 0.211],\n",
    "                      [0.941, 0.352, 0.156],\n",
    "                      [0.964, 0.572, 0.117],\n",
    "                      [0.980, 0.686, 0.250],\n",
    "                      [0.545, 0.772, 0.247],\n",
    "                      [0.215, 0.701, 0.290],\n",
    "                      [0, 0.576, 0.270],\n",
    "                      [0, 0.650, 0.611],\n",
    "                      [0.145, 0.662, 0.878]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmax = 4\n",
    "sortwindow = [15, 100]\n",
    "\n",
    "fig, axs = plt.subplots(len(trial_types),len(uniquelabels),\n",
    "                        figsize=(2*len(uniquelabels),2*len(trial_types)))\n",
    "cbar_ax = fig.add_axes([.94, .3, .01, .4])\n",
    "cbar_ax.tick_params(width=0.5) \n",
    "\n",
    "numroisincluster = np.nan*np.ones((len(uniquelabels),))\n",
    "\n",
    "for c, cluster in enumerate(uniquelabels):\n",
    "    for k, tempkey in enumerate(trial_types):\n",
    "        temp = populationdata[np.where(newlabels==cluster)[0], k*window_size:(k+1)*window_size]\n",
    "        numroisincluster[c] = temp.shape[0]\n",
    "        sortresponse = np.argsort(np.mean(temp[:,sortwindow[0]:sortwindow[1]], axis=1))[::-1]\n",
    "        sns.heatmap(temp[sortresponse],\n",
    "                    ax=axs[k, cluster],                                                                                                                                                                                                 \n",
    "                    cmap=plt.get_cmap('coolwarm'),\n",
    "                    vmin=-cmax,\n",
    "                    vmax=cmax,\n",
    "                    cbar=(cluster==0),\n",
    "                    cbar_ax=cbar_ax if (cluster==0) else None,\n",
    "                    cbar_kws={'label': 'Normalized fluorescence'})\n",
    "        axs[k, cluster].grid(False) \n",
    "        if k==len(trial_types)-1:\n",
    "            axs[k, cluster].set_xticks([0, pre_window_size,\n",
    "                                        pre_window_size + frames_to_reward, window_size])\n",
    "        else:\n",
    "            axs[k, cluster].set_xticks([])\n",
    "        axs[k, cluster].tick_params(width=0.5)    \n",
    "        axs[k, cluster].set_xticklabels([str(int((a-pre_window_size+0.0)/framerate))\n",
    "                                         for a in [0, pre_window_size,\n",
    "                                                   pre_window_size + frames_to_reward, window_size]])\n",
    "        axs[k, cluster].set_yticks([])\n",
    "        axs[k, cluster].axvline(pre_window_size, linestyle='--', color='k', linewidth=0.5)\n",
    "        axs[k, cluster].axvline(pre_window_size + frames_to_reward, linestyle='--', color='k', linewidth=0.5)\n",
    "        if cluster==0:\n",
    "            axs[k, 0].set_ylabel('%s\\nNeurons'%(tempkey))\n",
    "    axs[0, cluster].set_title('Cluster %d\\n(n=%d)'%(cluster+1, numroisincluster[c]))\n",
    "    \n",
    "fig.text(0.5, 0.05, 'Time from cue (s)', fontsize=12,\n",
    "         horizontalalignment='center', verticalalignment='center', rotation='horizontal')\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "fig.subplots_adjust(left=0.03)\n",
    "fig.subplots_adjust(right=0.93)\n",
    "fig.subplots_adjust(bottom=0.2)\n",
    "fig.subplots_adjust(top=0.83)                                    \n",
    "\n",
    "#fig.savefig(os.path.join(summaryfigdir, dt_string+'_'+clusterkey+'_' +  trial_types[0] + '_'+trial_types[1]+'_clusters_spectral_clustering.png'),format='png', dpi=300,bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axs = plt.subplots(1,len(uniquelabels),\n",
    "                        figsize=(2.5*len(uniquelabels),1.3*len(trial_types)))\n",
    "\n",
    "for c, cluster in enumerate(uniquelabels):\n",
    "\n",
    "    for k, tempkey in enumerate(trial_types):\n",
    "        temp = populationdata[np.where(newlabels==cluster)[0], k*window_size:(k+1)*window_size]\n",
    "        numroisincluster[c] = temp.shape[0]\n",
    "        sortresponse = np.argsort(np.mean(temp[:,sortwindow[0]:sortwindow[1]], axis=1))[::-1]\n",
    "        sns.lineplot(x=\"variable\", y=\"value\",data = pd.DataFrame(temp[sortresponse]).melt(),\n",
    "                    ax = axs[cluster],\n",
    "                    palette=plt.get_cmap('coolwarm'),label = tempkey,legend = False)\n",
    "        axs[cluster].grid(False)\n",
    "        if k==len(trial_types)-1:\n",
    "            axs[cluster].set_xticks([0, pre_window_size,\n",
    "                                        pre_window_size + frames_to_reward, window_size])\n",
    "        else:\n",
    "            axs[cluster].set_xticks([])\n",
    "        axs[cluster].tick_params(width=0.5)    \n",
    "        axs[cluster].set_xticklabels([str(int((a-pre_window_size+0.0)/framerate))\n",
    "                                         for a in [0, pre_window_size,\n",
    "                                                   pre_window_size + frames_to_reward, window_size]])\n",
    "        axs[cluster].axvline(pre_window_size, linestyle='--', color='k', linewidth=0.5)\n",
    "        axs[cluster].axvline(pre_window_size + frames_to_reward, linestyle='--', color='k', linewidth=0.5)\n",
    "        axs[cluster].spines['right'].set_visible(False)\n",
    "        axs[cluster].spines['top'].set_visible(False)\n",
    "        if cluster==0:\n",
    "            axs[cluster].set_ylabel('Normalized fluorescence')\n",
    "        else:\n",
    "            axs[cluster].set_ylabel('')\n",
    "    axs[cluster].set_title('Cluster %d\\n(n=%d)'%(cluster+1, numroisincluster[c]))\n",
    "    axs[0].legend()\n",
    "fig.text(0.5, 0.05, 'Time from cue (s)', fontsize=12,\n",
    "         horizontalalignment='center', verticalalignment='center', rotation='horizontal')\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "fig.subplots_adjust(left=0.03)\n",
    "fig.subplots_adjust(right=0.93)\n",
    "fig.subplots_adjust(bottom=0.2)\n",
    "fig.subplots_adjust(top=0.83)\n",
    "\n",
    "#fig.savefig(os.path.join(summaryfigdir, dt_string+'_'+ clusterkey+'_' + trial_types[0] + '_'+trial_types[1]+'_clusters_average_spectral_clustering.png'), format='png', dpi=300,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusterpairs = len(uniquelabels)*(len(uniquelabels)-1)/2\n",
    "\n",
    "numrows = int(np.ceil(num_clusterpairs**0.5))\n",
    "numcols = int(np.ceil(num_clusterpairs/np.ceil(num_clusterpairs**0.5)))\n",
    "fig, axs = plt.subplots(numrows, numcols, figsize=(3*numrows, 3*numcols))\n",
    "\n",
    "tempsum = 0\n",
    "for c1, cluster1 in enumerate(uniquelabels):\n",
    "    for c2, cluster2 in enumerate(uniquelabels):\n",
    "        if cluster1>=cluster2:\n",
    "            continue\n",
    "        temp1 = transformed_data[np.where(newlabels==cluster1)[0], :num_retained_pcs]\n",
    "        temp2 = transformed_data[np.where(newlabels==cluster2)[0], :num_retained_pcs]\n",
    "        X = np.concatenate((temp1, temp2), axis=0)\n",
    "        tsne = TSNE(n_components=2, init='random',\n",
    "                    random_state=0, perplexity=100)\n",
    "        Y = tsne.fit_transform(X)\n",
    "        ax = axs[tempsum/numcols,\n",
    "                 tempsum - tempsum/numcols*numcols]   \n",
    "        ax.scatter(Y[:np.sum(newlabels==cluster1),0],\n",
    "                   Y[:np.sum(newlabels==cluster1),1],\n",
    "                   color=colors_for_cluster[cluster1], label='Cluster %d'%(cluster1+1), alpha=1)\n",
    "        ax.scatter(Y[np.sum(newlabels==cluster1):,0],\n",
    "                   Y[np.sum(newlabels==cluster1):,1],\n",
    "                   color=colors_for_cluster[cluster2], label='Cluster %d'%(cluster2+1), alpha=1)\n",
    "\n",
    "        ax.set_xlabel('tsne dimension 1')\n",
    "        ax.set_ylabel('tsne dimension 2')\n",
    "        ax.legend()\n",
    "        tempsum += 1\n",
    "\n",
    "        fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
